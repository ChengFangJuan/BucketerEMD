

#Agent
HiddenLayer = 64
LearningRateBR = 0.05
LearningRateAR = 0.1
Gamma = 0.95
Epsilon = 0.06
EpsilonDecay = 0.06
EpsilonMin = 0
MiniBatchSize = 128
Penalty = -1
Eta = 0.1
MRLSize = 200000
MSLSize = 2000000
Omega = 0.003
TargetModelUpdateRate = 150

#Environment
Decksize = 6
Playercount = 2
Choices = 4
MaxRounds = 2
Suits = 2
MaxRaises = 3
ActionSpace = 2
TotalActionSpace = 3


#Utils
Buffersize = 40000
Seed = 1234

#Common
MaxEpisodes = 10000
Episodes = 400000
TestEpisodes = 1000

